{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Dense, \\\n",
    "                         Dropout, Flatten, Input, Concatenate, \\\n",
    "                         Conv2DTranspose, ELU, Activation, ZeroPadding2D, \\\n",
    "                         Cropping2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential, load_model\n",
    "from sklearn import preprocessing\n",
    "import time\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### HELPERS #####\n",
    "def save_png(array, file_name='test'):\n",
    "    ''' save rgb numpy array to png '''\n",
    "    sp.misc.imsave('images/'+file_name+'.png', array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1015, 3, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "data = np.rollaxis(np.load('data.npy'),2,5)\n",
    "data[:,:,:,:,[0,1,2]] = data[:,:,:,:,[2,1,0]]\n",
    "print data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split into training/test\n",
    "sample_range = range(data.shape[0])\n",
    "np.random.shuffle(sample_range)\n",
    "training_idx = sample_range[:int(data.shape[0]*0.8)]\n",
    "test_idx = sample_range[int(data.shape[0]*0.8):]\n",
    "X1_train = data[training_idx,0,:,:,:]\n",
    "X2_train = data[training_idx,1,:,:,:]\n",
    "y_train = data[training_idx,2,:,:,:]\n",
    "X1_test = data[test_idx,0,:,:,:]\n",
    "X2_test = data[test_idx,1,:,:,:]\n",
    "y_test = data[test_idx,2,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "input_a = Input(shape=(64,64,3)) #parent 1 input\n",
    "pad_1a = ZeroPadding2D(1)(input_a)\n",
    "conv_1a = Convolution2D(32, (4, 4), strides=2)(pad_1a)\n",
    "activ_1a = ELU()(conv_1a)\n",
    "norm_1a = BatchNormalization()(activ_1a)\n",
    "drop_1a = Dropout(0.1)(norm_1a)\n",
    "pad_2a = ZeroPadding2D(1)(drop_1a)\n",
    "conv_2a = Convolution2D(64, (4, 4), strides=2)(pad_2a)\n",
    "activ_2a = ELU()(conv_2a)\n",
    "norm_2a = BatchNormalization()(activ_2a)\n",
    "drop_2a = Dropout(0.1)(norm_2a)\n",
    "\n",
    "input_b = Input(shape=(64,64,3)) #parent 2 input\n",
    "pad_1b = ZeroPadding2D(1)(input_b)\n",
    "conv_1b = Convolution2D(32, (4, 4), strides=2)(pad_1b)\n",
    "activ_1b = ELU()(conv_1b)\n",
    "norm_1b = BatchNormalization()(activ_1b)\n",
    "drop_1b = Dropout(0.1)(norm_1b)\n",
    "pad_2b = ZeroPadding2D(1)(drop_1b)\n",
    "conv_2b = Convolution2D(64, (4, 4), strides=2)(pad_2b)\n",
    "activ_2b = ELU()(conv_2b)\n",
    "norm_2b = BatchNormalization()(activ_2b)\n",
    "drop_2b = Dropout(0.1)(norm_2b)\n",
    "\n",
    "input_z = Input(shape=(4,4,64)) #random input\n",
    "conv_1z = Conv2DTranspose(64, (4,4), strides=2, padding='same')(input_z)\n",
    "activ_1z = ELU()(conv_1z)\n",
    "norm_1z = BatchNormalization()(activ_1z)\n",
    "conv_2z = Conv2DTranspose(32, (4, 4), strides=2, padding='same')(norm_1z)\n",
    "activ_2z = ELU()(conv_2z)\n",
    "norm_2z = BatchNormalization()(activ_2z)\n",
    "\n",
    "concat_c = Concatenate()([drop_2a, drop_2b, norm_2z]) #concatenate parents and random input\n",
    "deconv_1c = Conv2DTranspose(32, (4,4), strides=2, padding='same')(concat_c)\n",
    "activ_1c = ELU()(deconv_1c)\n",
    "norm_1c = BatchNormalization()(activ_1c)\n",
    "deconv_2c = Conv2DTranspose(3, (4,4), strides=2, padding='same')(norm_1c)\n",
    "out = Activation('tanh')(deconv_2c)\n",
    "\n",
    "model = Model(inputs=[input_a, input_b, input_z], outputs=out)\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_152 (InputLayer)          (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_153 (InputLayer)          (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_164 (ZeroPadding (None, 66, 66, 3)    0           input_152[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_166 (ZeroPadding (None, 66, 66, 3)    0           input_153[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 32, 32, 32)   1568        zero_padding2d_164[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 32, 32, 32)   1568        zero_padding2d_166[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "elu_345 (ELU)                   (None, 32, 32, 32)   0           conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "elu_347 (ELU)                   (None, 32, 32, 32)   0           conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_345 (BatchN (None, 32, 32, 32)   128         elu_345[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_347 (BatchN (None, 32, 32, 32)   128         elu_347[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_154 (InputLayer)          (None, 4, 4, 64)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_201 (Dropout)           (None, 32, 32, 32)   0           batch_normalization_345[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_203 (Dropout)           (None, 32, 32, 32)   0           batch_normalization_347[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_148 (Conv2DTra (None, 8, 8, 64)     65600       input_154[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_165 (ZeroPadding (None, 34, 34, 32)   0           dropout_201[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_167 (ZeroPadding (None, 34, 34, 32)   0           dropout_203[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "elu_349 (ELU)                   (None, 8, 8, 64)     0           conv2d_transpose_148[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 16, 16, 64)   32832       zero_padding2d_165[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 16, 16, 64)   32832       zero_padding2d_167[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_349 (BatchN (None, 8, 8, 64)     256         elu_349[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "elu_346 (ELU)                   (None, 16, 16, 64)   0           conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "elu_348 (ELU)                   (None, 16, 16, 64)   0           conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_149 (Conv2DTra (None, 16, 16, 32)   32800       batch_normalization_349[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_346 (BatchN (None, 16, 16, 64)   256         elu_346[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_348 (BatchN (None, 16, 16, 64)   256         elu_348[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "elu_350 (ELU)                   (None, 16, 16, 32)   0           conv2d_transpose_149[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_202 (Dropout)           (None, 16, 16, 64)   0           batch_normalization_346[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_204 (Dropout)           (None, 16, 16, 64)   0           batch_normalization_348[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_350 (BatchN (None, 16, 16, 32)   128         elu_350[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 16, 16, 160)  0           dropout_202[0][0]                \n",
      "                                                                 dropout_204[0][0]                \n",
      "                                                                 batch_normalization_350[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_150 (Conv2DTra (None, 32, 32, 32)   81952       concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "elu_351 (ELU)                   (None, 32, 32, 32)   0           conv2d_transpose_150[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_351 (BatchN (None, 32, 32, 32)   128         elu_351[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_151 (Conv2DTra (None, 64, 64, 3)    1539        batch_normalization_351[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 64, 64, 3)    0           conv2d_transpose_151[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 251,971\n",
      "Trainable params: 251,331\n",
      "Non-trainable params: 640\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 39s - loss: 0.3992\n",
      "Epoch 2/100\n",
      " - 17s - loss: 0.2682\n",
      "Epoch 3/100\n",
      " - 19s - loss: 0.2305\n",
      "Epoch 4/100\n",
      " - 19s - loss: 0.2125\n",
      "Epoch 5/100\n",
      " - 19s - loss: 0.2012\n",
      "Epoch 6/100\n",
      " - 19s - loss: 0.1929\n",
      "Epoch 7/100\n",
      " - 20s - loss: 0.1879\n",
      "Epoch 8/100\n",
      " - 18s - loss: 0.1830\n",
      "Epoch 9/100\n",
      " - 18s - loss: 0.1792\n",
      "Epoch 10/100\n",
      " - 17s - loss: 0.1759\n",
      "Epoch 11/100\n",
      " - 17s - loss: 0.1732\n",
      "Epoch 12/100\n",
      " - 20s - loss: 0.1707\n",
      "Epoch 13/100\n",
      " - 17s - loss: 0.1685\n",
      "Epoch 14/100\n",
      " - 17s - loss: 0.1665\n",
      "Epoch 15/100\n",
      " - 17s - loss: 0.1649\n",
      "Epoch 16/100\n",
      " - 17s - loss: 0.1635\n",
      "Epoch 17/100\n",
      " - 17s - loss: 0.1623\n",
      "Epoch 18/100\n",
      " - 17s - loss: 0.1614\n",
      "Epoch 19/100\n",
      " - 17s - loss: 0.1605\n",
      "Epoch 20/100\n",
      " - 17s - loss: 0.1599\n",
      "Epoch 21/100\n",
      " - 17s - loss: 0.1595\n",
      "Epoch 22/100\n",
      " - 17s - loss: 0.1588\n",
      "Epoch 23/100\n",
      " - 17s - loss: 0.1584\n",
      "Epoch 24/100\n",
      " - 17s - loss: 0.1580\n",
      "Epoch 25/100\n",
      " - 17s - loss: 0.1574\n",
      "Epoch 26/100\n",
      " - 17s - loss: 0.1572\n",
      "Epoch 27/100\n",
      " - 17s - loss: 0.1569\n",
      "Epoch 28/100\n",
      " - 17s - loss: 0.1568\n",
      "Epoch 29/100\n",
      " - 17s - loss: 0.1561\n",
      "Epoch 30/100\n",
      " - 17s - loss: 0.1559\n",
      "Epoch 31/100\n",
      " - 17s - loss: 0.1554\n",
      "Epoch 32/100\n",
      " - 17s - loss: 0.1553\n",
      "Epoch 33/100\n",
      " - 17s - loss: 0.1553\n",
      "Epoch 34/100\n",
      " - 19s - loss: 0.1547\n",
      "Epoch 35/100\n",
      " - 27s - loss: 0.1543\n",
      "Epoch 36/100\n",
      " - 24s - loss: 0.1539\n",
      "Epoch 37/100\n",
      " - 20s - loss: 0.1536\n",
      "Epoch 38/100\n",
      " - 19s - loss: 0.1535\n",
      "Epoch 39/100\n",
      " - 21s - loss: 0.1533\n",
      "Epoch 40/100\n",
      " - 21s - loss: 0.1531\n",
      "Epoch 41/100\n",
      " - 19s - loss: 0.1531\n",
      "Epoch 42/100\n",
      " - 17s - loss: 0.1525\n",
      "Epoch 43/100\n",
      " - 18s - loss: 0.1520\n",
      "Epoch 44/100\n",
      " - 18s - loss: 0.1520\n",
      "Epoch 45/100\n",
      " - 19s - loss: 0.1520\n",
      "Epoch 46/100\n",
      " - 17s - loss: 0.1514\n",
      "Epoch 47/100\n",
      " - 22s - loss: 0.1508\n",
      "Epoch 48/100\n",
      " - 19s - loss: 0.1509\n",
      "Epoch 49/100\n",
      " - 17s - loss: 0.1503\n",
      "Epoch 50/100\n",
      " - 21s - loss: 0.1499\n",
      "Epoch 51/100\n",
      " - 20s - loss: 0.1496\n",
      "Epoch 52/100\n",
      " - 18s - loss: 0.1489\n",
      "Epoch 53/100\n",
      " - 17s - loss: 0.1484\n",
      "Epoch 54/100\n",
      " - 17s - loss: 0.1485\n",
      "Epoch 55/100\n",
      " - 17s - loss: 0.1479\n",
      "Epoch 56/100\n",
      " - 17s - loss: 0.1478\n",
      "Epoch 57/100\n",
      " - 18s - loss: 0.1477\n",
      "Epoch 58/100\n",
      " - 22s - loss: 0.1479\n",
      "Epoch 59/100\n",
      " - 18s - loss: 0.1475\n",
      "Epoch 60/100\n",
      " - 18s - loss: 0.1471\n",
      "Epoch 61/100\n",
      " - 19s - loss: 0.1461\n",
      "Epoch 62/100\n",
      " - 17s - loss: 0.1470\n",
      "Epoch 63/100\n",
      " - 18s - loss: 0.1463\n",
      "Epoch 64/100\n",
      " - 18s - loss: 0.1455\n",
      "Epoch 65/100\n",
      " - 17s - loss: 0.1457\n",
      "Epoch 66/100\n",
      " - 18s - loss: 0.1452\n",
      "Epoch 67/100\n",
      " - 18s - loss: 0.1449\n",
      "Epoch 68/100\n",
      " - 17s - loss: 0.1448\n",
      "Epoch 69/100\n",
      " - 18s - loss: 0.1450\n",
      "Epoch 70/100\n",
      " - 19s - loss: 0.1436\n",
      "Epoch 71/100\n",
      " - 18s - loss: 0.1435\n",
      "Epoch 72/100\n",
      " - 17s - loss: 0.1441\n",
      "Epoch 73/100\n",
      " - 17s - loss: 0.1432\n",
      "Epoch 74/100\n",
      " - 17s - loss: 0.1424\n",
      "Epoch 75/100\n",
      " - 17s - loss: 0.1420\n",
      "Epoch 76/100\n",
      " - 17s - loss: 0.1416\n",
      "Epoch 77/100\n",
      " - 17s - loss: 0.1405\n",
      "Epoch 78/100\n",
      " - 17s - loss: 0.1404\n",
      "Epoch 79/100\n",
      " - 17s - loss: 0.1403\n",
      "Epoch 80/100\n",
      " - 17s - loss: 0.1396\n",
      "Epoch 81/100\n",
      " - 17s - loss: 0.1396\n",
      "Epoch 82/100\n",
      " - 17s - loss: 0.1389\n",
      "Epoch 83/100\n",
      " - 17s - loss: 0.1386\n",
      "Epoch 84/100\n",
      " - 17s - loss: 0.1385\n",
      "Epoch 85/100\n",
      " - 17s - loss: 0.1371\n",
      "Epoch 86/100\n",
      " - 17s - loss: 0.1373\n",
      "Epoch 87/100\n",
      " - 17s - loss: 0.1372\n",
      "Epoch 88/100\n",
      " - 17s - loss: 0.1366\n",
      "Epoch 89/100\n",
      " - 17s - loss: 0.1357\n",
      "Epoch 90/100\n",
      " - 17s - loss: 0.1353\n",
      "Epoch 91/100\n",
      " - 17s - loss: 0.1350\n",
      "Epoch 92/100\n",
      " - 17s - loss: 0.1341\n",
      "Epoch 93/100\n",
      " - 17s - loss: 0.1335\n",
      "Epoch 94/100\n",
      " - 19s - loss: 0.1330\n",
      "Epoch 95/100\n",
      " - 18s - loss: 0.1331\n",
      "Epoch 96/100\n",
      " - 18s - loss: 0.1323\n",
      "Epoch 97/100\n",
      " - 18s - loss: 0.1316\n",
      "Epoch 98/100\n",
      " - 17s - loss: 0.1323\n",
      "Epoch 99/100\n",
      " - 18s - loss: 0.1313\n",
      "Epoch 100/100\n",
      " - 20s - loss: 0.1310\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "Z_train = np.random.uniform(size=(X1_train.shape[0], 4, 4, 64))\n",
    "history = model.fit([X1_train, X2_train, Z_train], \\\n",
    "                    y_train, \\\n",
    "                    batch_size = 256, \\\n",
    "                    epochs = 100, \\\n",
    "                    validation_split = 0, \\\n",
    "                    verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### SAVE MODEL #####\n",
    "'''\n",
    "model0 : 12/7/2017 (no random z)\n",
    "model1 : 12/11/2017 (random z)\n",
    "model2 : 12/11/2017 (random z fixed)\n",
    "'''\n",
    "model.save('models/model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### LOAD MODEL #####\n",
    "model = load_model('model/model0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict test set and save\n",
    "Z_test = np.random.uniform(size=(X1_test.shape[0], 4, 4, 64))\n",
    "predictions = model.predict([X1_test, X2_test, Z_test])\n",
    "\n",
    "for j in range(len(predictions)):\n",
    "    save_png(predictions[j], file_name='z_100_epochs/'+str(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict test set and save, with zero for Z\n",
    "Z_test = np.zeros((X1_test.shape[0], 4, 4, 64))\n",
    "predictions = model.predict([X1_test, X2_test, Z_test])\n",
    "\n",
    "for j in range(len(predictions)):\n",
    "    save_png(predictions[j], file_name='noz_100_epochs/'+str(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBb+ISIn5/wiJ/I4svVE9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x177715cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save test results to .npy file\n",
    "def save_results(X1_test, X2_test, predictions, file_name='supervised_z0.npy'):\n",
    "    ''' stack test set inputs and outputs to numpy array and save '''\n",
    "    x1 = np.rollaxis(X1_test, 3, 1)[:,np.newaxis,[2,1,0],:,:]\n",
    "    x2 = np.rollaxis(X2_test, 3, 1)[:,np.newaxis,[2,1,0],:,:]\n",
    "    y_pred = np.rollaxis(np.array(predictions), 3, 1)[:,np.newaxis,[2,1,0],:,:]\n",
    "    stacked = np.hstack([x1,x2,y_pred])\n",
    "    np.save(file_name, stacked)\n",
    "\n",
    "save_results(X1_test, X2_test, predictions, file_name='supervised_z0.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(filename):\n",
    "    ''' preprocess image to get ready for keras input '''\n",
    "    npy = np.rollaxis(np.load(filename), 0, 3)\n",
    "    npy[:,:,[0,1,2]] = npy[:,:,[2,1,0]]\n",
    "    return npy.reshape(1,64,64,3)\n",
    "\n",
    "def generate_n_children(model, parent_idx, num_children=10):\n",
    "    ''' predict multiple children from one parent pair '''\n",
    "    parent1 = process_image('GAN_data/parent'+str(parent_idx)+'a.npy')\n",
    "    parent2 = process_image('GAN_data/parent'+str(parent_idx)+'b.npy')\n",
    "    for i in range(num_children):\n",
    "        z = np.random.uniform(size=(1,4,4,64))\n",
    "        prediction = model.predict([parent1, parent2, z])[0]\n",
    "        save_png(prediction, file_name='GAN_compare/'+str(parent_idx)+'/'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    generate_n_children(model, i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
